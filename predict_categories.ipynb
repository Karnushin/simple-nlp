{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "import re\n",
    "import datetime\n",
    "import multiprocessing\n",
    "import joblib\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "english_stopwords = stopwords.words(\"english\")\n",
    "stopwords_rus_dict = Counter(russian_stopwords)\n",
    "stopwords_eng_dict = Counter(english_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemainLettersNumsInLowerCase(data, columns_list):\n",
    "    '''Simple change text in dataframe inplace\n",
    "    Remain only letters and numbers and making string in lower case\n",
    "    \n",
    "    Parameters:\n",
    "        data - dataframe\n",
    "        columns_list - list of columns' names where changes must be\n",
    "    '''\n",
    "    \n",
    "    for column in columns_list:\n",
    "        data[column] = data[column].apply(lambda x: re.sub('[\\W]+', ' ', x.lower()))\n",
    "\n",
    "def ThrowStopWords(series_column, stopwords_dict):\n",
    "    '''Get dataframe column with text and throw out stopwords\n",
    "    Return changed column\n",
    "    \n",
    "    Parameters:\n",
    "        series_column - series where words are contained\n",
    "        stopwords_dict - Counter dict of stopwords -words that must be dropped\n",
    "        \n",
    "    Return:\n",
    "        changed series\n",
    "    '''\n",
    "    \n",
    "    series = []\n",
    "    for i, string in enumerate(series_column):\n",
    "        series.append(' '.join(word for word in string.split() if not stopwords_dict[word]))\n",
    "    return series\n",
    "\n",
    "def TF_IDF(train, test, column, **params):\n",
    "    '''Apply TF_IDF for the choosen column in train and test\n",
    "    for train and test where there is text\n",
    "    \n",
    "    Parameters:\n",
    "        train, test - 2 dataframes\n",
    "        column - column's name in those dataframe where tf_idf should be done\n",
    "        **params - dict of params of tf_idf method\n",
    "        \n",
    "    Return:\n",
    "        Encoded in tf_idf train and test samples\n",
    "    '''\n",
    "\n",
    "    vectorizer = TfidfVectorizer(**params)\n",
    "    train_column_tfidf = vectorizer.fit_transform(train[column])\n",
    "    test_column_tfidf = vectorizer.transform(test[column])\n",
    "    \n",
    "    return train_column_tfidf, test_column_tfidf\n",
    "\n",
    "def DivideOnFirstLevel(text):\n",
    "    '''Need to divide category by first level\n",
    "    Function is mostly usefull for this task\n",
    "    \n",
    "    Parameters:\n",
    "        text - description in a view: a|b|c, where a - 1st level category, b - 2d etc\n",
    "    \n",
    "    Return:\n",
    "        Category's number\n",
    "    '''\n",
    "    \n",
    "    #it can be extented to 2, 3 etc levels on need\n",
    "    d = {r'Бытовая электроника':0, r'Для дома и дачи':1,r'Личные вещи':2,r'Хобби и отдых':3}\n",
    "    \n",
    "    return d[re.split(r'[|]', text)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Картина</td>\n",
       "      <td>Гобелен. Размеры 139х84см.</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Стулья из прессованной кожи</td>\n",
       "      <td>Продам недорого 4 стула из светлой прессованно...</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Домашняя мини баня</td>\n",
       "      <td>Мини баня МБ-1(мини сауна), предназначена для ...</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Эксклюзивная коллекция книг \"Трансаэро\" + подарок</td>\n",
       "      <td>Продам эксклюзивную коллекцию книг, выпущенную...</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ноутбук aser</td>\n",
       "      <td>Продаётся ноутбук ACER e5-511C2TA. Куплен в ко...</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title  \\\n",
       "item_id                                                      \n",
       "0                                                  Картина   \n",
       "1                              Стулья из прессованной кожи   \n",
       "2                                       Домашняя мини баня   \n",
       "3        Эксклюзивная коллекция книг \"Трансаэро\" + подарок   \n",
       "4                                             Ноутбук aser   \n",
       "\n",
       "                                               description    price  \\\n",
       "item_id                                                               \n",
       "0                               Гобелен. Размеры 139х84см.   1000.0   \n",
       "1        Продам недорого 4 стула из светлой прессованно...   1250.0   \n",
       "2        Мини баня МБ-1(мини сауна), предназначена для ...  13000.0   \n",
       "3        Продам эксклюзивную коллекцию книг, выпущенную...   4000.0   \n",
       "4        Продаётся ноутбук ACER e5-511C2TA. Куплен в ко...  19000.0   \n",
       "\n",
       "         category_id  \n",
       "item_id               \n",
       "0                 19  \n",
       "1                 22  \n",
       "2                 37  \n",
       "3                 43  \n",
       "4                  1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv',index_col='item_id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = pd.read_csv('category.csv')\n",
    "catlevel_1 = category['name'].apply(DivideOnFirstLevel)\n",
    "dictlevel_1 = dict(zip(list(range(df['category_id'].unique().shape[0])), catlevel_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exchange category_id in sample\n",
    "df['category_id'] = df['category_id'].apply(lambda x: dictlevel_1[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape df before: (489517, 4)\n",
      "Shape df after: (489200, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape df before: {df.shape}')\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "print(f'Shape df after: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#during attempts it seems to be better\n",
    "df['fulldiscr'] = df['title'] + ' ' + df['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape df: (489200, 5)\n",
      "Shape df_frac: (244600, 5)\n"
     ]
    }
   ],
   "source": [
    "#to speed up training\n",
    "print(f'Shape df: {df.shape}')\n",
    "df_frac = df.sample(frac=0.5, random_state=SEED)\n",
    "print(f'Shape df_frac: {df_frac.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, y_train, y_test = train_test_split(df_frac.drop(['title', 'description', 'category_id'], axis=1) \n",
    "                                                , df_frac['category_id'], test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "RemainLettersNumsInLowerCase(train, ['fulldiscr'])\n",
    "RemainLettersNumsInLowerCase(test, ['fulldiscr'])\n",
    "\n",
    "train['fulldiscr'] = ThrowStopWords(train['fulldiscr'], stopwords_rus_dict)\n",
    "test['fulldiscr'] = ThrowStopWords(test['fulldiscr'], stopwords_rus_dict)\n",
    "\n",
    "#train['description'] = ThrowStopWords(train['description'], stopwords_rus_dict)\n",
    "#test['description'] = ThrowStopWords(test['description'], stopwords_rus_dict)\n",
    "#train['title'] = ThrowStopWords(train['title'], stopwords_rus_dict)\n",
    "#test['title'] = ThrowStopWords(test['title'], stopwords_rus_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of got unique words 310639\n"
     ]
    }
   ],
   "source": [
    "s = ''\n",
    "for row in train['fulldiscr']:\n",
    "    s += ' ' + row\n",
    "\n",
    "cnt = len(set(s.split()))\n",
    "print(f'Count of got unique words {cnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_title_tfidf, test_title_tfidf = TF_IDF(train, test,'title', 5)\n",
    "#train_descr_scaled, test_descr_tfidf = TF_IDF(train, test,'description', 5)\n",
    "\n",
    "params1 = {'min_df': 5}\n",
    "params2 = {'min_df': 5, 'max_df': 0.99, 'ngram_range': (1, 2)}\n",
    "\n",
    "train_descr_tfidf, test_descr_tfidf = TF_IDF(train, test, 'fulldiscr', **params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = hstack([train_descr_tfidf, train['price'].values.reshape(-1,1)])\n",
    "test_all = hstack([test_descr_tfidf, test['price'].values.reshape(-1,1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-st base attempt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.28501\ttest-merror:0.28346\n",
      "Multiple eval metrics have been passed: 'test-merror' will be used for early stopping.\n",
      "\n",
      "Will train until test-merror hasn't improved in 25 rounds.\n",
      "[25]\ttrain-merror:0.17444\ttest-merror:0.17584\n",
      "[50]\ttrain-merror:0.14408\ttest-merror:0.14708\n",
      "[75]\ttrain-merror:0.12335\ttest-merror:0.12704\n",
      "[100]\ttrain-merror:0.10922\ttest-merror:0.11415\n",
      "[125]\ttrain-merror:0.09902\ttest-merror:0.10429\n",
      "[150]\ttrain-merror:0.09166\ttest-merror:0.09792\n",
      "[175]\ttrain-merror:0.08533\ttest-merror:0.09366\n",
      "[199]\ttrain-merror:0.08041\ttest-merror:0.08958\n",
      "Time taken:1:08:39.044626\n"
     ]
    }
   ],
   "source": [
    "#ordinary parameters for tf_idf params1\n",
    "params = {'objective': 'multi:softmax'\n",
    "          , 'n_jobs': multiprocessing.cpu_count()\n",
    "          , 'num_class': y_train.unique().shape[0]\n",
    "          , 'tree_method': 'hist'\n",
    "          , 'grow_policy': 'lossguide'\n",
    "          , 'max_depth': 0\n",
    "          , 'max_leaves': 31\n",
    "          , 'reg_alpha': 1.5\n",
    "          , 'reg_lambda': 2\n",
    "          , 'learning_rate': 0.1\n",
    "          , 'subsample': 0.8\n",
    "          , 'colsample_bytree': 0.8\n",
    "          , 'gamma': 1\n",
    "          , 'eval_metric': 'merror'\n",
    "          , 'random_state': SEED\n",
    "         }\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "dtrain = xgb.DMatrix(scipy.sparse.csc_matrix(train_all), label=y_train)\n",
    "dtest = xgb.DMatrix(scipy.sparse.csc_matrix(test_all), label=y_test)\n",
    "\n",
    "clf = xgb.train(params, dtrain, num_boost_round=200\n",
    "                , early_stopping_rounds=25, verbose_eval=25\n",
    "                , evals= [(dtrain, 'train'), (dtest, 'test')])\n",
    "\n",
    "print(f'Time taken:{datetime.datetime.now() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.9195932134096484\n",
      "test accuracy: 0.9104251839738349\n"
     ]
    }
   ],
   "source": [
    "#tf_idf params1\n",
    "print(f'train accuracy: {accuracy_score(y_train, clf.predict(dtrain))}')\n",
    "print(f'test accuracy: {accuracy_score(y_test, clf.predict(dtest))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.save_model('xgb_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Little modifications and one more attempt**\n",
    "\n",
    "Here I use less trees to speed up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.28418\ttest-merror:0.28269\n",
      "Multiple eval metrics have been passed: 'test-merror' will be used for early stopping.\n",
      "\n",
      "Will train until test-merror hasn't improved in 25 rounds.\n",
      "[25]\ttrain-merror:0.17303\ttest-merror:0.17537\n",
      "[50]\ttrain-merror:0.14271\ttest-merror:0.14636\n",
      "[75]\ttrain-merror:0.12328\ttest-merror:0.12657\n",
      "[99]\ttrain-merror:0.10961\ttest-merror:0.11490\n",
      "Time taken:1:04:04.572511\n"
     ]
    }
   ],
   "source": [
    "#ordinary parameters for \n",
    "params = {'objective': 'multi:softmax'\n",
    "          , 'n_jobs': multiprocessing.cpu_count()\n",
    "          , 'num_class': y_train.unique().shape[0]\n",
    "          , 'tree_method': 'hist'\n",
    "          , 'grow_policy': 'lossguide'\n",
    "          , 'max_depth': 0\n",
    "          , 'max_leaves': 31\n",
    "          , 'reg_alpha': 1.5\n",
    "          , 'reg_lambda': 2\n",
    "          , 'learning_rate': 0.1\n",
    "          , 'subsample': 0.8\n",
    "          , 'colsample_bytree': 0.75\n",
    "          , 'gamma': 1\n",
    "          , 'eval_metric': 'merror'\n",
    "          , 'random_state': SEED\n",
    "         }\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "dtrain = xgb.DMatrix(scipy.sparse.csc_matrix(train_all), label=y_train)\n",
    "dtest = xgb.DMatrix(scipy.sparse.csc_matrix(test_all), label=y_test)\n",
    "\n",
    "clf2 = xgb.train(params, dtrain, num_boost_round=100\n",
    "                , early_stopping_rounds=25, verbose_eval=25\n",
    "                , evals= [(dtrain, 'train'), (dtest, 'test')])\n",
    "\n",
    "print(f'Time taken:{datetime.datetime.now() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.890392477514309\n",
      "test accuracy: 0.8850981193785773\n"
     ]
    }
   ],
   "source": [
    "#tf_idf params2\n",
    "print(f'train accuracy: {accuracy_score(y_train, clf2.predict(dtrain))}')\n",
    "print(f'test accuracy: {accuracy_score(y_test, clf2.predict(dtest))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2.save_model('xgb_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is a desired metric (not by me) and baseline is 0.9 on test. It can be much better if tune parameters using for example optuna or hyperopt but it's not for my laptop using so much data also tf_idf should be tuned to get better score.\n",
    "\n",
    "Anyways this already beat baseline without almost overfitting on test created from 'train' dataset but I'm sure there will no problems and getting worse score if do the same steps on full 'train' and 'test' csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
